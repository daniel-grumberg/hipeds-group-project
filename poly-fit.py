from sklearn.preprocessing import PolynomialFeatures
from sklearn import linear_model
import numpy as np
import matplotlib.pyplot as plt

poly = PolynomialFeatures(degree=3)

def train():
	#X is the independent variable (bivariate in this case)
	X = np.array([
				[95.6266,  88.5283, 	73.66114855,	102.3528099, 61.48446798, 	77.87678242, 98.3375310898,  103.362762928, 90.3969287872, 34.7963571548, 40.8519864082, 33.4429383278, 32.4984073639, 41.2608742714, 51.6548037529, 54.7623515129, 51.9164919853],    # Sensor 1
				[96.4362,  81.5422, 	75.39074421,	88.72048855, 67.12712049, 	85.68245173, 94.2036747932,  81.6181063652, 100.978946686, 44.6750879288, 62.2899770737, 43.8532233238, 44.5565104485, 62.8378868103, 50.3708958626, 50.5753397942, 54.9667954445],	# 2
				[99.5928,  88.4588, 	77.41473913, 	101.0648131, 68.34560633, 	88.45880032, 98.1494426727,  73.4158158302, 98.1494426727, 68.6359167099, 54.5538187027, 51.176404953,  51.6384482384, 54.0549755096, 55.0199508667, 54.6928405762, 54.2635083199], 	# 3
				[100.9623, 85.6661, 	71.92746401, 	80.70628643, 68.44782829, 	61.68891191, 70.6762671471,  56.4060807228, 103.808450699, 44.0413117409, 67.4174308777, 44.1926002502, 44.417488575,  65.5815243721, 61.6889119148, 58.0702543259, 60.5399370193], 	# 4
				[99.6092,  87.6901,     75.93865395, 	90.69132805, 65.58152437, 	84.45987701, 79.0952682495,  53.5765767097, 99.9853491783, 41.964161396,  50.8983612061, 42.0173168182, 42.2953605652, 50.8860945702, 55.7927489281, 55.8418154716, 55.805015564], 	# 5
				[92.2696,  90.8263,     77.10807323, 	87.70644665, 76.69509649, 	85.88689566, 80.710375309,   55.4819941521, 99.4169950485, 45.3620195389, 49.8025417328, 48.2446789742, 47.058904171,  50.1828074455, 51.2418270111, 54.2307972908, 54.1776418686], 	# 6
				[103.3464, 90.123,      70.36551237, 	78.25295925, 67.69138575, 	77.46789455, 82.8488588333,  105,			105, 		   45.1739311218, 52.1004915237, 44.7445988655, 44.7773098946, 52.5788903236, 52.7874231339, 53.8341760635, 54.7419071198], 	# 7
				[99.7973,  86.79462671, 75.7178545, 	73.48532677, 56.45923615, 	68.51325035, 48.4491229057,  80.5222868919, 87.2607588768, 37.4909281731, 47.0916152, 	 44.1762447357, 40.4717206955, 46.3883280754, 61.9260668755, 64.3466830254, 66.5587663651], 	# 8
				[100.6518, 89.64457512, 75.46025515, 	78.47784758, 64.34668303, 	67.70774126, 20.0682163239,  20.8900809288, 99.5355725288, 39.1019463539, 53.6828875542, 39.4822120667, 40.9869194031, 53.662443161,  64.7923707962, 64.2771720886, 64.7760152817], 	# 9
				[100.5128, 73.24817181, 72.63075113, 	62.35948801, 75.92229843, 	53.35577726, 42.2381162643,  42.3403382301, 93.4145212173, 37.8507494926, 43.4238910675, 44.1762447357, 41.1627411842, 37.8671050072, 61.5335345268, 63.0096197128, 56.1811923981],	# 10
				[101.3061, 87.56742477, 68.81991625, 	70.72533369, 65.70010185, 	64.79645967, 55.6700825691,  45.6727743149, 100.361526012, 36.3092422485, 48.878455162,  36.2887978554, 36.2887978554, 48.0197906494, 57.3506116867, 52.0677804947, 54.9667954445], 	# 11
				[99.8668,  87.92724609, 75.42345524, 	77.27980614, 75.13723373, 	21.00865841, 21.7283010483,  21.3848352432, 101.187479496, 41.3467407227, 42.274916172,  40.9869194031, 40.0791883469, 43.096780777,  63.8314843178, 66.4933443069, 65.8391237259], 	# 12
				[101.1343, 89.88581896, 81.16832972, 	56.47559166, 75.59518814, 	79.56140041, 67.691385746,   64.7433042526, 101.784455776, 38.1737709045, 39.7847890854, 38.1778597832, 38.9465689659, 38.9465689659, 69.2860484123, 67.4501419067, 67.9653406143], 	# 13
				[97.6342,  81.66717291, 75.08407831, 	49.82298613, 71.94381952, 	73.96781445, 68.1207180023,  60.110604763,  95.5080270767, 49.7698307037, 41.7392730713, 48.9970326424, 48.9479660988, 50.6448507309, 53.9200425148, 57.0930123329, 60.3845596313], 	# 14
				[100.4147, 89.78359699, 79.30380106, 	55.12217283, 78.7027359, 	78.32247019, 56.8313241005,  56.7659020424, 98.3743309975, 39.3922567368, 51.9124031067, 43.4934020042, 39.4249677658, 51.9655585289, 67.9489850998, 68.3946728706, 68.4110283852] 	# 15
		]).T
	#print(X.shape) # (n_samples, n_features) = (n x 15)
		
	#vector is the dependent data
	vector = np.array([[0, 0.17457, 0.34914, 0.34914, 0.34914, 0.34914, 0.34914, 0.42642, 0.0, 0.8505, 0.756, 0.8505, 0.8505, 0.756, 0.567, 0.567, 0.567]]).T
	#print(vector.shape) # (n_samples, n_targets) = (n x 1)
		
	X_ = poly.fit_transform(X)

	clf = linear_model.LinearRegression()
	clf.fit(X_, vector)
	
	# Return the fitted model
	return clf


clf = train()

def estimate(measurements):
	# predict is an independent variable for which we'd like to predict the value
	#predict = np.array([[73.9351034164,  92.4699902534, 99.4169950485, 65.8227682114,  68.4110283852, 79.9007773399,  56.1321258545,  65.0131702423,  60.6094479561, 44.2130446434, 34.6246242523,  65.8391237259,  73.8983035088,  50.710272789, 57.6940774918]]) # Should be 0.40434
	predict_ = poly.fit_transform(measurements)
	#print(predict.shape)
	print("Predicting volume...")
	volume = clf.predict(predict_)
	print(volume)
	return volume

	
# ESTIMATE VOLUME
measurements1 = np.array([[73.9351034164,  92.4699902534, 99.4169950485, 65.8227682114,  68.4110283852, 79.9007773399,  56.1321258545,  65.0131702423,  60.6094479561, 44.2130446434, 34.6246242523,  65.8391237259,  73.8983035088,  50.710272789, 57.6940774918]]) # Should be 0.40434
r1 = estimate(measurements1) # 0.40434

error = abs(r1 - 0.40434)

measurements2 = np.array([[52.9918670654, 50.865650177, 54.0917754173, 60.6053590775, 55.8091044426, 54.2103528976,  56.0094594955, 65.2217030525, 64.8128151894, 57.779943943, 62.1877551079, 65.8391237259, 67.4501419067, 56.9212794304, 68.4273838997]]) # Should be 0.567
r2 = estimate(measurements2) # 0.567

error = error + abs(r2 - 0.567)

measurements3 = np.array([[47.0057487488, 52.6647567749, 54.5538187027, 66.059923172, 51.2949824333, 50.1296520233, 53.8341760635, 47.6109027863, 53.1472444534, 43.8000679016, 47.6068139076, 42.6183819771, 38.9629244804, 45.6850409508, 51.1068940163]])
r3 = estimate(measurements3) # 0.756

error = error + abs(r3 - 0.756)

error = (error / 3) / 1.89
print("Average error in m^3 =")
print(error)

# [[0.50243809]] with 2 degrees = 21.6% error, 0.1m^3
# [[0.46493694]] with 3 degrees = 13.9419% error, 0.06m^3
# [[0.43734088]] with 4 degrees = 7.84% error, 0.03m^3
# Anymore and likely to overfit, cba to actually get enough data to check
